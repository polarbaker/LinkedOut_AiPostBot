# Enhanced LinkedIn Generator Environment Configuration
# Copy this file to .env and update with your specific settings
# Run: cp .env.template .env

# ===== LLM Provider Configuration =====

# Primary LLM provider selection: 'gemini', 'openai', or 'mock'
# - 'gemini' uses Google's Gemini models with OpenAI fallback
# - 'openai' uses OpenAI models exclusively
# - 'mock' uses mock responses for testing (no API calls)
LLM_PROVIDER=openai

# API Keys
OPENAI_API_KEY=your_openai_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here

# ===== Application Configuration =====

# Server configuration
PORT=5003                   # HTTP port for Flask server
DEBUG=false                 # Set to true for development debugging
FLASK_APP=app.py           # Flask application entry point

# Logging configuration
LOG_LEVEL=INFO             # Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL

# ===== Testing Configuration =====

# Set to 'true' for CI/CD pipelines and automated tests
# MOCK_MODE=true

# ===== Rate Limiting =====

# Maximum requests per minute per IP address
RATE_LIMIT=60

# ===== Development Helper Flags =====

# Uncomment to use specific model for development/testing
# GEMINI_MODEL_OVERRIDE=gemini-1.5-flash
